{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Unet-baseline.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dlif7ntXWHmK"
      },
      "source": [
        "# U-net:  A fully convolutional network \n",
        "## Satelite Image Detection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWc4hbp6WHmM",
        "outputId": "0afe5454-54f5-4c29-beb0-73a4763c2daa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from collections import defaultdict\n",
        "\n",
        "import tifffile as tiff\n",
        "import shapely.wkt\n",
        "import shapely.affinity\n",
        "from shapely.wkt import loads as wkt_loads\n",
        "from shapely.geometry import MultiPolygon, Polygon\n",
        "\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D, Reshape, core, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as K\n",
        "K.set_image_dim_ordering('th')\n",
        "from sklearn.metrics import jaccard_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVgL1acAYtHk"
      },
      "source": [
        "Number of Classification 10\n",
        "\n",
        "1)Buildings - large building, residential, non-residential, fuel storage facility, fortified building\n",
        "\n",
        "2) Misc. Manmade structures \n",
        "\n",
        "3)Road \n",
        "\n",
        "4) Track - poor/dirt/cart track, footpath/trail\n",
        "\n",
        "5) Trees - woodland, hedgerows, groups of trees, standalone trees\n",
        "\n",
        "6) Crops - contour ploughing/cropland, grain (wheat) crops, row (potatoes, \n",
        "turnips) crops\n",
        "\n",
        "7) Waterway \n",
        "\n",
        "8) Standing water\n",
        "\n",
        "9) Vehicle Large - large vehicle (e.g. lorry, truck,bus), logistics vehicle\n",
        "\n",
        "10) Vehicle Small - small vehicle (car, van), motorbike\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im2BjXtcWHmT"
      },
      "source": [
        "N_Cls = 10\n",
        "inDir = '../input'\n",
        "DF = pd.read_csv(inDir + '/train_wkt_v4.csv')\n",
        "GS = pd.read_csv(inDir + '/grid_sizes.csv', names=['ImageId', 'Xmax', 'Ymin'], skiprows=1)\n",
        "SB = pd.read_csv(os.path.join(inDir, 'sample_submission.csv'))\n",
        "ISZ = 160\n",
        "smooth = 1e-12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhr0JPwYWHmZ"
      },
      "source": [
        "def _convert_coordinates_to_raster(coords, img_size, xymax):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    Xmax, Ymax = xymax\n",
        "    H, W = img_size\n",
        "    W1 = 1.0 * W * W / (W + 1)\n",
        "    H1 = 1.0 * H * H / (H + 1)\n",
        "    xf = W1 / Xmax\n",
        "    yf = H1 / Ymax\n",
        "    coords[:, 1] *= yf\n",
        "    coords[:, 0] *= xf\n",
        "    coords_int = np.round(coords).astype(np.int32)\n",
        "    return coords_int\n",
        "\n",
        "\n",
        "def _get_xmax_ymin(grid_sizes_panda, imageId):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    xmax, ymin = grid_sizes_panda[grid_sizes_panda.ImageId == imageId].iloc[0, 1:].astype(float)\n",
        "    return (xmax, ymin)\n",
        "\n",
        "\n",
        "def _get_polygon_list(wkt_list_pandas, imageId, cType):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    df_image = wkt_list_pandas[wkt_list_pandas.ImageId == imageId]\n",
        "    multipoly_def = df_image[df_image.ClassType == cType].MultipolygonWKT\n",
        "    polygonList = None\n",
        "    if len(multipoly_def) > 0:\n",
        "        assert len(multipoly_def) == 1\n",
        "        polygonList = wkt_loads(multipoly_def.values[0])\n",
        "    return polygonList\n",
        "\n",
        "\n",
        "def _get_and_convert_contours(polygonList, raster_img_size, xymax):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    perim_list = []\n",
        "    interior_list = []\n",
        "    if polygonList is None:\n",
        "        return None\n",
        "    for k in range(len(polygonList)):\n",
        "        poly = polygonList[k]\n",
        "        perim = np.array(list(poly.exterior.coords))\n",
        "        perim_c = _convert_coordinates_to_raster(perim, raster_img_size, xymax)\n",
        "        perim_list.append(perim_c)\n",
        "        for pi in poly.interiors:\n",
        "            interior = np.array(list(pi.coords))\n",
        "            interior_c = _convert_coordinates_to_raster(interior, raster_img_size, xymax)\n",
        "            interior_list.append(interior_c)\n",
        "    return perim_list, interior_list\n",
        "\n",
        "\n",
        "def _plot_mask_from_contours(raster_img_size, contours, class_value=1):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    img_mask = np.zeros(raster_img_size, np.uint8)\n",
        "    if contours is None:\n",
        "        return img_mask\n",
        "    perim_list, interior_list = contours\n",
        "    cv2.fillPoly(img_mask, perim_list, class_value)\n",
        "    cv2.fillPoly(img_mask, interior_list, 0)\n",
        "    return img_mask\n",
        "\n",
        "\n",
        "def generate_mask_for_image_and_class(raster_size, imageId, class_type, grid_sizes_panda=GS, wkt_list_pandas=DF):\n",
        "    # __author__ = visoft\n",
        "    # https://www.kaggle.com/visoft/dstl-satellite-imagery-feature-detection/export-pixel-wise-mask\n",
        "    xymax = _get_xmax_ymin(grid_sizes_panda, imageId)\n",
        "    polygon_list = _get_polygon_list(wkt_list_pandas, imageId, class_type)\n",
        "    contours = _get_and_convert_contours(polygon_list, raster_size, xymax)\n",
        "    mask = _plot_mask_from_contours(raster_size, contours, 1)\n",
        "    return mask\n",
        "\n",
        "\n",
        "def M(image_id):\n",
        "    # __author__ = amaia\n",
        "    # https://www.kaggle.com/aamaia/dstl-satellite-imagery-feature-detection/rgb-using-m-bands-example\n",
        "    filename = os.path.join(inDir, 'sixteen_band', '{}_M.tif'.format(image_id))\n",
        "    img = tiff.imread(filename)\n",
        "    img = np.rollaxis(img, 0, 3)\n",
        "    return img\n",
        "\n",
        "\n",
        "def stretch_n(bands, lower_percent=5, higher_percent=95):\n",
        "    out = np.zeros_like(bands)\n",
        "    n = bands.shape[2]\n",
        "    for i in range(n):\n",
        "        a = 0  # np.min(band)\n",
        "        b = 1  # np.max(band)\n",
        "        c = np.percentile(bands[:, :, i], lower_percent)\n",
        "        d = np.percentile(bands[:, :, i], higher_percent)\n",
        "        t = a + (bands[:, :, i] - c) * (b - a) / (d - c)\n",
        "        t[t < a] = a\n",
        "        t[t > b] = b\n",
        "        out[:, :, i] = t\n",
        "\n",
        "    return out.astype(np.float32)\n",
        "\n",
        "\n",
        "def jaccard_coef(y_true, y_pred):\n",
        "    # __author__ = Vladimir Iglovikov\n",
        "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
        "\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "\n",
        "    return K.mean(jac)\n",
        "\n",
        "\n",
        "def jaccard_coef_int(y_true, y_pred):\n",
        "    # __author__ = Vladimir Iglovikov\n",
        "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
        "\n",
        "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
        "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return K.mean(jac)\n",
        "\n",
        "\n",
        "def stick_all_train():\n",
        "    print (\"let's stick all imgs together\")\n",
        "    s = 835\n",
        "\n",
        "    x = np.zeros((5 * s, 5 * s, 8))\n",
        "    y = np.zeros((5 * s, 5 * s, N_Cls))\n",
        "\n",
        "    ids = sorted(DF.ImageId.unique())\n",
        "    print (len(ids))\n",
        "    for i in range(5):\n",
        "        for j in range(5):\n",
        "            id = ids[5 * i + j]\n",
        "\n",
        "            img = M(id)\n",
        "            img = stretch_n(img)\n",
        "            print (img.shape, id, np.amax(img), np.amin(img))\n",
        "            x[s * i:s * i + s, s * j:s * j + s, :] = img[:s, :s, :]\n",
        "            for z in range(N_Cls):\n",
        "                y[s * i:s * i + s, s * j:s * j + s, z] = generate_mask_for_image_and_class(\n",
        "                    (img.shape[0], img.shape[1]), id, z + 1)[:s, :s]\n",
        "\n",
        "    print (np.amax(y), np.amin(y))\n",
        "\n",
        "    np.save('../input/data/x_trn_%d' % N_Cls, x)\n",
        "    np.save('../input/data/y_trn_%d' % N_Cls, y)\n",
        "\n",
        "\n",
        "def get_patches(img, msk, amt=10000, aug=True):\n",
        "    is2 = int(1.0 * ISZ)\n",
        "    xm, ym = img.shape[0] - is2, img.shape[1] - is2\n",
        "\n",
        "    x, y = [], []\n",
        "\n",
        "    tr = [0.4, 0.1, 0.1, 0.15, 0.3, 0.95, 0.1, 0.05, 0.001, 0.005]\n",
        "    for i in range(amt):\n",
        "        xc = random.randint(0, xm)\n",
        "        yc = random.randint(0, ym)\n",
        "\n",
        "        im = img[xc:xc + is2, yc:yc + is2]\n",
        "        ms = msk[xc:xc + is2, yc:yc + is2]\n",
        "\n",
        "        for j in range(N_Cls):\n",
        "            sm = np.sum(ms[:, :, j])\n",
        "            if 1.0 * sm / is2 ** 2 > tr[j]:\n",
        "                if aug:\n",
        "                    if random.uniform(0, 1) > 0.5:\n",
        "                        im = im[::-1]\n",
        "                        ms = ms[::-1]\n",
        "                    if random.uniform(0, 1) > 0.5:\n",
        "                        im = im[:, ::-1]\n",
        "                        ms = ms[:, ::-1]\n",
        "\n",
        "                x.append(im)\n",
        "                y.append(ms)\n",
        "\n",
        "    x, y = 2 * np.transpose(x, (0, 3, 1, 2)) - 1, np.transpose(y, (0, 3, 1, 2))\n",
        "    print (x.shape, y.shape, np.amax(x), np.amin(x), np.amax(y), np.amin(y))\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def make_val():\n",
        "    print (\"let's pick some samples for validation\")\n",
        "    img = np.load('../input/data/x_trn_%d.npy' % N_Cls)\n",
        "    msk = np.load('../input/data/y_trn_%d.npy' % N_Cls)\n",
        "    x, y = get_patches(img, msk, amt=3000)\n",
        "\n",
        "    np.save('../input/data/x_tmp_%d' % N_Cls, x)\n",
        "    np.save('../input/data/y_tmp_%d' % N_Cls, y)\n",
        "\n",
        "def calc_jacc(model):\n",
        "    img = np.load('../input/data/x_tmp_%d.npy' % N_Cls)\n",
        "    msk = np.load('../input/data/y_tmp_%d.npy' % N_Cls)\n",
        "\n",
        "    prd = model.predict(img, batch_size=4)\n",
        "    print (prd.shape, msk.shape)\n",
        "    avg, trs = [], []\n",
        "\n",
        "    for i in range(N_Cls):\n",
        "        t_msk = msk[:, i, :, :]\n",
        "        t_prd = prd[:, i, :, :]\n",
        "        t_msk = t_msk.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n",
        "        t_prd = t_prd.reshape(msk.shape[0] * msk.shape[2], msk.shape[3])\n",
        "\n",
        "        m, b_tr = 0, 0\n",
        "        for j in range(10):\n",
        "            tr = j / 10.0\n",
        "            pred_binary_mask = t_prd > tr\n",
        "\n",
        "            jk = jaccard_similarity_score(t_msk, pred_binary_mask)\n",
        "            if jk > m:\n",
        "                m = jk\n",
        "                b_tr = tr\n",
        "        print (i, m, b_tr)\n",
        "        avg.append(m)\n",
        "        trs.append(b_tr)\n",
        "\n",
        "    score = sum(avg) / 10.0\n",
        "    return score, trs\n",
        "\n",
        "\n",
        "def mask_for_polygons(polygons, im_size):\n",
        "    # __author__ = Konstantin Lopuhin\n",
        "    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n",
        "    img_mask = np.zeros(im_size, np.uint8)\n",
        "    if not polygons:\n",
        "        return img_mask\n",
        "    int_coords = lambda x: np.array(x).round().astype(np.int32)\n",
        "    exteriors = [int_coords(poly.exterior.coords) for poly in polygons]\n",
        "    interiors = [int_coords(pi.coords) for poly in polygons\n",
        "                 for pi in poly.interiors]\n",
        "    cv2.fillPoly(img_mask, exteriors, 1)\n",
        "    cv2.fillPoly(img_mask, interiors, 0)\n",
        "    return img_mask\n",
        "\n",
        "\n",
        "def mask_to_polygons(mask, epsilon=5, min_area=1.):\n",
        "    # __author__ = Konstantin Lopuhin\n",
        "    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n",
        "\n",
        "    # first, find contours with cv2: it's much faster than shapely\n",
        "    image, contours, hierarchy = cv2.findContours(\n",
        "        ((mask == 1) * 255).astype(np.uint8),\n",
        "        cv2.RETR_CCOMP, cv2.CHAIN_APPROX_TC89_KCOS)\n",
        "    # create approximate contours to have reasonable submission size\n",
        "    approx_contours = [cv2.approxPolyDP(cnt, epsilon, True)\n",
        "                       for cnt in contours]\n",
        "    if not contours:\n",
        "        return MultiPolygon()\n",
        "    # now messy stuff to associate parent and child contours\n",
        "    cnt_children = defaultdict(list)\n",
        "    child_contours = set()\n",
        "    assert hierarchy.shape[0] == 1\n",
        "    # http://docs.opencv.org/3.1.0/d9/d8b/tutorial_py_contours_hierarchy.html\n",
        "    for idx, (_, _, _, parent_idx) in enumerate(hierarchy[0]):\n",
        "        if parent_idx != -1:\n",
        "            child_contours.add(idx)\n",
        "            cnt_children[parent_idx].append(approx_contours[idx])\n",
        "    # create actual polygons filtering by area (removes artifacts)\n",
        "    all_polygons = []\n",
        "    for idx, cnt in enumerate(approx_contours):\n",
        "        if idx not in child_contours and cv2.contourArea(cnt) >= min_area:\n",
        "            assert cnt.shape[1] == 1\n",
        "            poly = Polygon(\n",
        "                shell=cnt[:, 0, :],\n",
        "                holes=[c[:, 0, :] for c in cnt_children.get(idx, [])\n",
        "                       if cv2.contourArea(c) >= min_area])\n",
        "            all_polygons.append(poly)\n",
        "    # approximating polygons might have created invalid ones, fix them\n",
        "    all_polygons = MultiPolygon(all_polygons)\n",
        "    if not all_polygons.is_valid:\n",
        "        all_polygons = all_polygons.buffer(0)\n",
        "        # Sometimes buffer() converts a simple Multipolygon to just a Polygon,\n",
        "        # need to keep it a Multi throughout\n",
        "        if all_polygons.type == 'Polygon':\n",
        "            all_polygons = MultiPolygon([all_polygons])\n",
        "    return all_polygons\n",
        "\n",
        "\n",
        "def get_scalers(im_size, x_max, y_min):\n",
        "    # __author__ = Konstantin Lopuhin\n",
        "    # https://www.kaggle.com/lopuhin/dstl-satellite-imagery-feature-detection/full-pipeline-demo-poly-pixels-ml-poly\n",
        "    h, w = im_size  # they are flipped so that mask_for_polygons works correctly\n",
        "    h, w = float(h), float(w)\n",
        "    w_ = 1.0 * w * (w / (w + 1))\n",
        "    h_ = 1.0 * h * (h / (h + 1))\n",
        "    return w_ / x_max, h_ / y_min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsOWB4dkWHmf"
      },
      "source": [
        "## Define U-net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cyVNuBAWHmg"
      },
      "source": [
        "def get_unet():\n",
        "    inputs = Input((8, ISZ, ISZ))\n",
        "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same', init='he_normal')(inputs)\n",
        "    conv1 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(pool1)\n",
        "    conv2 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(pool2)\n",
        "    conv3 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(pool3)\n",
        "    conv4 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(pool4)\n",
        "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same')(conv5)\n",
        "\n",
        "    up6 = merge([UpSampling2D(size=(2, 2))(conv5), conv4], mode='concat', concat_axis=1)\n",
        "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(up6)\n",
        "    conv6 = Convolution2D(256, 3, 3, activation='relu', border_mode='same')(conv6)\n",
        "\n",
        "    up7 = merge([UpSampling2D(size=(2, 2))(conv6), conv3], mode='concat', concat_axis=1)\n",
        "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(up7)\n",
        "    conv7 = Convolution2D(128, 3, 3, activation='relu', border_mode='same')(conv7)\n",
        "\n",
        "    up8 = merge([UpSampling2D(size=(2, 2))(conv7), conv2], mode='concat', concat_axis=1)\n",
        "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(up8)\n",
        "    conv8 = Convolution2D(64, 3, 3, activation='relu', border_mode='same')(conv8)\n",
        "\n",
        "    up9 = merge([UpSampling2D(size=(2, 2))(conv8), conv1], mode='concat', concat_axis=1)\n",
        "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(up9)\n",
        "    conv9 = Convolution2D(32, 3, 3, activation='relu', border_mode='same')(conv9)\n",
        "\n",
        "    conv10 = Convolution2D(N_Cls, 1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(input=inputs, output=conv10)\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', \\\n",
        "                  metrics=[jaccard_coef, jaccard_coef_int, 'accuracy','categorical_crossentropy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jI_uhjcOWHml"
      },
      "source": [
        "## Training and predicting\n",
        "\n",
        "* You don't have to download the provided weights to start your training, it's just optional\n",
        "* nb_epoch used in the original script is 1, which is way **SMALLER** to have a decent result. Try at least 20 and observe the metrics on validation set to determine the best epoch needed.\n",
        "* Once your training/predicting finished, a new weights file will be saved in the \"weights/\" folder. You can leverage it by loading it as intial weights if you want to continue training your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DfpIYREWHmm"
      },
      "source": [
        "def train_net():\n",
        "    print (\"start train net\")\n",
        "    x_val, y_val = np.load('../input/data/x_tmp_%d.npy' % N_Cls), np.load('../input/data/y_tmp_%d.npy' % N_Cls)\n",
        "    img = np.load('../input/data/x_trn_%d.npy' % N_Cls)\n",
        "    msk = np.load('../input/data/y_trn_%d.npy' % N_Cls)\n",
        "\n",
        "    x_trn, y_trn = get_patches(img, msk)\n",
        "\n",
        "    model = get_unet()\n",
        "    model.load_weights('../input/weights/unet_10_jk0.7878')\n",
        "    model_checkpoint = ModelCheckpoint('../input/weights/unet_tmp.hdf5', monitor='loss', save_best_only=True)\n",
        "    for i in range(1):\n",
        "        model.fit(x_trn, y_trn, batch_size=64, nb_epoch=20, verbose=1, shuffle=True,\n",
        "                  callbacks=[model_checkpoint], validation_data=(x_val, y_val))\n",
        "        del x_trn\n",
        "        del y_trn\n",
        "        x_trn, y_trn = get_patches(img, msk)\n",
        "        score, trs = calc_jacc(model)\n",
        "        print ('val jk', score)\n",
        "        model.save_weights('../input/weights/unet_10_jk%.4f' % score)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def predict_id(id, model, trs):\n",
        "    img = M(id)\n",
        "    x = stretch_n(img)\n",
        "\n",
        "    cnv = np.zeros((960, 960, 8)).astype(np.float32)\n",
        "    prd = np.zeros((N_Cls, 960, 960)).astype(np.float32)\n",
        "    cnv[:img.shape[0], :img.shape[1], :] = x\n",
        "\n",
        "    for i in range(0, 6):\n",
        "        line = []\n",
        "        for j in range(0, 6):\n",
        "            line.append(cnv[i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ])\n",
        "\n",
        "        x = 2 * np.transpose(line, (0, 3, 1, 2)) - 1\n",
        "        tmp = model.predict(x, batch_size=4)\n",
        "        for j in range(tmp.shape[0]):\n",
        "            prd[:, i * ISZ:(i + 1) * ISZ, j * ISZ:(j + 1) * ISZ] = tmp[j]\n",
        "\n",
        "    # trs = [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1]\n",
        "    for i in range(N_Cls):\n",
        "        prd[i] = prd[i] > trs[i]\n",
        "\n",
        "    return prd[:, :img.shape[0], :img.shape[1]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vh9UY8qsWHmr"
      },
      "source": [
        "def predict_test(model, trs):\n",
        "    print (\"predict test\")\n",
        "    for i, id in enumerate(sorted(set(SB['ImageId'].tolist()))):\n",
        "        msk = predict_id(id, model, trs)\n",
        "        np.save('../output/msk/10_%s' % id, msk)\n",
        "        if i % 100 == 0: \n",
        "            print (i, id)\n",
        "\n",
        "\n",
        "def make_submit():\n",
        "    print (\"make submission file\")\n",
        "    df = pd.read_csv(os.path.join(inDir, 'sample_submission.csv'))\n",
        "    print (df.head())\n",
        "    for idx, row in df.iterrows():\n",
        "        id = row[0]\n",
        "        kls = row[1] - 1\n",
        "\n",
        "        msk = np.load('../output/msk/10_%s.npy' % id)[kls]\n",
        "        pred_polygons = mask_to_polygons(msk)\n",
        "        x_max = GS.loc[GS['ImageId'] == id, 'Xmax'].as_matrix()[0]\n",
        "        y_min = GS.loc[GS['ImageId'] == id, 'Ymin'].as_matrix()[0]\n",
        "\n",
        "        x_scaler, y_scaler = get_scalers(msk.shape, x_max, y_min)\n",
        "\n",
        "        scaled_pred_polygons = shapely.affinity.scale(pred_polygons, xfact=1.0 / x_scaler, yfact=1.0 / y_scaler,\n",
        "                                                      origin=(0, 0, 0))\n",
        "\n",
        "        df.iloc[idx, 2] = shapely.wkt.dumps(scaled_pred_polygons)\n",
        "        if idx % 100 == 0: \n",
        "            print (idx)\n",
        "    print (df.head())\n",
        "    df.to_csv('../output/unet.csv', index=False)\n",
        "    \n",
        "    \n",
        "def check_predict(id='6120_2_3'):\n",
        "    model = get_unet()\n",
        "    model.load_weights('../input/weights/unet_10_jk0.7448')\n",
        "\n",
        "    msk = predict_id(id, model, [0.4, 0.1, 0.4, 0.3, 0.3, 0.5, 0.3, 0.6, 0.1, 0.1])\n",
        "    img = M(id)\n",
        "\n",
        "    plt.figure()\n",
        "    ax1 = plt.subplot(131)\n",
        "    ax1.set_title('image ID:6120_2_3')\n",
        "    ax1.imshow(img[:, :, 5], cmap=plt.get_cmap('gist_ncar'))\n",
        "    ax2 = plt.subplot(132)\n",
        "    ax2.set_title('predict bldg pixels')\n",
        "    ax2.imshow(msk[0], cmap=plt.get_cmap('gray'))\n",
        "    ax3 = plt.subplot(133)\n",
        "    ax3.set_title('predict bldg polygones')\n",
        "    ax3.imshow(mask_for_polygons(mask_to_polygons(msk[0], epsilon=1), img.shape[:2]), cmap=plt.get_cmap('gray'))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd259X3ZWHmx"
      },
      "source": [
        "## Data preprocessing\n",
        "\n",
        "This only needs to be run for once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO4Iw0qdWHmy",
        "outputId": "d996dc3b-afe8-4641-d72e-9fd96cd31877"
      },
      "source": [
        "stick_all_train()\n",
        "make_val()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "let's stick all imgs together\n",
            "25\n",
            "(837, 849, 8) 6010_1_2 1.0 0.0\n",
            "(837, 849, 8) 6010_4_2 1.0 0.0\n",
            "(837, 848, 8) 6010_4_4 1.0 0.0\n",
            "(837, 848, 8) 6040_1_0 1.0 0.0\n",
            "(837, 848, 8) 6040_1_3 1.0 0.0\n",
            "(837, 848, 8) 6040_2_2 1.0 0.0\n",
            "(837, 846, 8) 6040_4_4 1.0 0.0\n",
            "(837, 851, 8) 6060_2_3 1.0 0.0\n",
            "(838, 835, 8) 6070_2_3 1.0 0.0\n",
            "(837, 848, 8) 6090_2_0 1.0 0.0\n",
            "(837, 848, 8) 6100_1_3 1.0 0.0\n",
            "(837, 848, 8) 6100_2_2 1.0 0.0\n",
            "(837, 848, 8) 6100_2_3 1.0 0.0\n",
            "(837, 849, 8) 6110_1_2 1.0 0.0\n",
            "(837, 849, 8) 6110_3_1 1.0 0.0\n",
            "(837, 849, 8) 6110_4_0 1.0 0.0\n",
            "(837, 851, 8) 6120_2_0 1.0 0.0\n",
            "(837, 851, 8) 6120_2_2 1.0 0.0\n",
            "(837, 849, 8) 6140_1_2 1.0 0.0\n",
            "(837, 849, 8) 6140_3_1 1.0 0.0\n",
            "(837, 851, 8) 6150_2_3 1.0 0.0\n",
            "(837, 848, 8) 6160_2_1 1.0 0.0\n",
            "(837, 848, 8) 6170_0_4 1.0 0.0\n",
            "(837, 848, 8) 6170_2_4 1.0 0.0\n",
            "(837, 848, 8) 6170_4_1 1.0 0.0\n",
            "1.0 0.0\n",
            "let's pick some samples for validation\n",
            "(1090, 8, 160, 160) (1090, 10, 160, 160) 1.0 -1.0 1.0 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydfUuED1WHm2"
      },
      "source": [
        "## Acutal training and prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "hluJNyxPWHm3",
        "outputId": "47913048-a080-4f37-a2cd-c50262a603ef"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "\n",
        "model = train_net()\n",
        "score, trs = calc_jacc(model)\n",
        "predict_test(model, trs)\n",
        "make_submit()\n",
        "\n",
        "print('totoal running time: %d second' %(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "start train net\n",
            "(3547, 8, 160, 160) (3547, 10, 160, 160) 1.0 -1.0 1.0 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer=\"he_normal\")`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "  import sys\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "  \n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "  if sys.path[0] == '':\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "  from ipykernel import kernelapp as app\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "  app.launch_new_instance()\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "  name=name)\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:38: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (1, 1), activation=\"sigmoid\")`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
            "/Users/junfang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 3547 samples, validate on 1090 samples\n",
            "Epoch 1/20\n",
            "3547/3547 [==============================] - 26073s - loss: 0.1596 - jaccard_coef: 0.1132 - jaccard_coef_int: 0.0986 - acc: 0.9427 - categorical_crossentropy: 60.8262 - val_loss: 0.1241 - val_jaccard_coef: 0.1351 - val_jaccard_coef_int: 0.1113 - val_acc: 0.9565 - val_categorical_crossentropy: 59.9918\n",
            "Epoch 2/20\n",
            "3547/3547 [==============================] - 7561s - loss: 0.1169 - jaccard_coef: 0.1555 - jaccard_coef_int: 0.1340 - acc: 0.9587 - categorical_crossentropy: 60.0079 - val_loss: 0.1120 - val_jaccard_coef: 0.1625 - val_jaccard_coef_int: 0.1373 - val_acc: 0.9599 - val_categorical_crossentropy: 59.7449\n",
            "Epoch 3/20\n",
            "3547/3547 [==============================] - 7488s - loss: 0.1083 - jaccard_coef: 0.1705 - jaccard_coef_int: 0.1501 - acc: 0.9616 - categorical_crossentropy: 59.8715 - val_loss: 0.1041 - val_jaccard_coef: 0.1700 - val_jaccard_coef_int: 0.1414 - val_acc: 0.9631 - val_categorical_crossentropy: 59.6247\n",
            "Epoch 4/20\n",
            "3547/3547 [==============================] - 7455s - loss: 0.1007 - jaccard_coef: 0.1848 - jaccard_coef_int: 0.1587 - acc: 0.9640 - categorical_crossentropy: 59.7137 - val_loss: 0.1009 - val_jaccard_coef: 0.1861 - val_jaccard_coef_int: 0.1555 - val_acc: 0.9642 - val_categorical_crossentropy: 59.3961\n",
            "Epoch 5/20\n",
            "3547/3547 [==============================] - 7454s - loss: 0.0963 - jaccard_coef: 0.1974 - jaccard_coef_int: 0.1697 - acc: 0.9654 - categorical_crossentropy: 59.5556 - val_loss: 0.0930 - val_jaccard_coef: 0.2054 - val_jaccard_coef_int: 0.1774 - val_acc: 0.9667 - val_categorical_crossentropy: 59.3805\n",
            "Epoch 6/20\n",
            "3547/3547 [==============================] - 7575s - loss: 0.0922 - jaccard_coef: 0.2114 - jaccard_coef_int: 0.1845 - acc: 0.9664 - categorical_crossentropy: 59.4268 - val_loss: 0.0945 - val_jaccard_coef: 0.2086 - val_jaccard_coef_int: 0.1854 - val_acc: 0.9663 - val_categorical_crossentropy: 59.2822\n",
            "Epoch 7/20\n",
            "3547/3547 [==============================] - 7778s - loss: 0.0890 - jaccard_coef: 0.2241 - jaccard_coef_int: 0.1999 - acc: 0.9675 - categorical_crossentropy: 59.2842 - val_loss: 0.0900 - val_jaccard_coef: 0.2194 - val_jaccard_coef_int: 0.1929 - val_acc: 0.9675 - val_categorical_crossentropy: 59.2718\n",
            "Epoch 8/20\n",
            "3547/3547 [==============================] - 9520s - loss: 0.0878 - jaccard_coef: 0.2369 - jaccard_coef_int: 0.2170 - acc: 0.9677 - categorical_crossentropy: 59.2131 - val_loss: 0.0917 - val_jaccard_coef: 0.2196 - val_jaccard_coef_int: 0.1951 - val_acc: 0.9669 - val_categorical_crossentropy: 59.2051\n",
            "Epoch 9/20\n",
            "3547/3547 [==============================] - 13719s - loss: 0.0920 - jaccard_coef: 0.2289 - jaccard_coef_int: 0.2088 - acc: 0.9665 - categorical_crossentropy: 59.3340 - val_loss: 0.0924 - val_jaccard_coef: 0.2189 - val_jaccard_coef_int: 0.1976 - val_acc: 0.9670 - val_categorical_crossentropy: 59.3557\n",
            "Epoch 10/20\n",
            "3547/3547 [==============================] - 10506s - loss: 0.0844 - jaccard_coef: 0.2560 - jaccard_coef_int: 0.2413 - acc: 0.9690 - categorical_crossentropy: 59.0646 - val_loss: 0.0866 - val_jaccard_coef: 0.2390 - val_jaccard_coef_int: 0.2184 - val_acc: 0.9689 - val_categorical_crossentropy: 58.9941\n",
            "Epoch 11/20\n",
            "3547/3547 [==============================] - 7414s - loss: 0.0804 - jaccard_coef: 0.2760 - jaccard_coef_int: 0.2620 - acc: 0.9701 - categorical_crossentropy: 58.8610 - val_loss: 0.0845 - val_jaccard_coef: 0.2557 - val_jaccard_coef_int: 0.2403 - val_acc: 0.9696 - val_categorical_crossentropy: 58.9812\n",
            "Epoch 12/20\n",
            "3547/3547 [==============================] - 7413s - loss: 0.0784 - jaccard_coef: 0.2895 - jaccard_coef_int: 0.2788 - acc: 0.9707 - categorical_crossentropy: 58.7576 - val_loss: 0.0827 - val_jaccard_coef: 0.2662 - val_jaccard_coef_int: 0.2525 - val_acc: 0.9700 - val_categorical_crossentropy: 58.8780\n",
            "Epoch 13/20\n",
            "1984/3547 [===============>..............] - ETA: 3141s - loss: 0.0757 - jaccard_coef: 0.2982 - jaccard_coef_int: 0.2878 - acc: 0.9716 - categorical_crossentropy: 59.0884"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUFBVj_2WHm8"
      },
      "source": [
        "## Follow up questions\n",
        "\n",
        "* Does larger epoch always help? What is the best epoch?\n",
        "* Only M images were used. Can we stack at other bands images?\n",
        "* Normally, train multiple models and simply averaging the predictions would yield better results for NN models. Would it be the case for our challenge?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHF-dCpPWHm9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}